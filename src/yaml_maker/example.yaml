# on convolutinal networks: /home/nex/Aplikacje/pylearn2/pylearn2/scripts/tutorials/convolutional_network
!obj:pylearn2.train.Train { # our experiment
    dataset: &train !obj:pylearn2.datasets.mnist.MNIST { # our data set will be a MNIST
        which_set: 'train', # 'train' or 'test' TODO: ???
        start: 0, # starting index
        stop: 200, # last index
    },
    model: %(model)s

    algorithm: !obj:pylearn2.training_algorithms.bgd.BGD { # trainig algorithm: Batch Gradient Descent
        batch_size: 10000, # just a batch size
        line_search_mode: 'exhaustive', # documentations says nothing about it For the directions to be
                                        # truly conjugate, you must use line_search_mode = ‘exhaustive’
                                        # and the objective function must be quadratic.
                                        # Using line_search_mode = ‘exhaustive’ on a non-quadratic objective
                                        # function implements nonlinear conjugate gradient descent.
        conjugate: 1, # "Passed through to the optimization.BatchGradientDescent’s conjugate parameter"
                      # If True, tries to pick conjugate gradient directions.
        updates_per_batch: 10,  # Passed through to the optimization.BatchGradientDescent’s max_iters parameter
                                # The maximum number of iterations to run, per code vector, if the optimization
                                # has still not converged. Default is 1000. TODO: what does it mean?
        monitoring_dataset: # A Dataset or a dictionary mapping string dataset names to Datasets
            {
                'train' : *train, # train set
                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'train', # refers to MNIST train set
                              start: 50000, # first index
                              stop: 52000 # last index
                          },
                'test'  : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'test', # refers to MNIST test set
                          }
            },
        termination_criterion: !obj:pylearn2.termination_criteria.And { # Keep learning until any of a set of criteria
                                                                        # wants to stop. Termination criterion
                                                                        # representing the logical conjunction of
                                                                        # several individual criteria. Optimization
                                                                        # continues only if every constituent criterion
                                                                        # returns True.
            criteria: [ # A sequence of callables representing termination criteria, with a return value of True
                        # indicating that training should continue.
                !obj:pylearn2.termination_criteria.MonitorBased {
                    channel_name: "valid_softmax_layer_misclass"    # Name of the channel to examine. If None and the monitor has
                                                        # only one channel, this channel will be used; otherwise,
                                                        # an error will be raised. For more info on monitors
                                                        # check the pylearn2 documentation
                },
                !obj:pylearn2.termination_criteria.EpochCounter {   # Learn for a fixed number of epochs.
                                                                    # A termination criterion that uses internal
                                                                    # state to trigger termination after a fixed
                                                                    # number of calls (epochs).
                    max_epochs: 20 # after how many epochs learning shall stop
                }
            ]
        }
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {   # A callback that saves a copy of the
                                                                            # model every time it achieves a new
                                                                            # minimal value of a monitoring channel.
                                                                            # Also stores the best model in memory.
             channel_name: 'valid_softmax_layer_misclass', # monitoring channel name
             save_path: "mlp_best.pkl" # here the learned model will be stored
        },
    ]
}
